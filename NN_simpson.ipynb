{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4496f287-58e7-4ea1-b073-3a680a0c6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGE_SIZE = 64  #for consistency in dataset convert every image to 64X64\n",
    "NUM_CLASSES = 10  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45a1e1b-7b0a-4f4a-9464-2dda8a457b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_path):\n",
    "    X, y = [],[]\n",
    "    class_names = sorted([d for d in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, d))])\n",
    "    label_map = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(folder_path, class_name)\n",
    "        img_files = os.listdir(class_dir)\n",
    "        if not img_files:\n",
    "            print(f\"Warning: No images found in {class_dir}\")\n",
    "        for img_file in img_files:\n",
    "            try:\n",
    "                img_path = os.path.join(class_dir, img_file)\n",
    "                img = Image.open(img_path).convert('L').resize((IMAGE_SIZE, IMAGE_SIZE))  # Grayscale conversion\n",
    "                img_array = np.asarray(img, dtype=np.float32) / 255.0  # Normalize to [0, 1]\n",
    "                X.append(img_array.flatten())  # Flatten to 1D\n",
    "                y.append(label_map[class_name])\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {img_path} due to {e}\")\n",
    "                continue\n",
    "\n",
    "    return np.array(X), np.array(y), label_map\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13e1cae-011f-4a64-89ae-60a4bbc3f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes):\n",
    "    one_hot = np.zeros((len(y), num_classes))\n",
    "    for i, label in enumerate(y):\n",
    "        one_hot[i, label] = 1\n",
    "    return one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96eb4be3-ea4b-4b82-9cc9-f3c4bc506527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, y):\n",
    "    assert len(X) == len(y)\n",
    "    permutation = np.random.permutation(len(X))\n",
    "    X_shuffled = X[permutation]\n",
    "    y_shuffled = y[permutation]\n",
    "    return X_shuffled, y_shuffled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf91d6a2-49f5-4176-8ad0-9ec8395b0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and shuffle training data\n",
    "X_train, y_train, label_map = load_data(\"simpson_train_augmented\")\n",
    "X_train, y_train = shuffle_data(X_train, y_train)\n",
    "\n",
    "# One-hot encode training labels\n",
    "y_train_encoded = one_hot_encode(y_train, NUM_CLASSES)\n",
    "\n",
    "# Load and shuffle test data\n",
    "X_test, y_test, _ = load_data(\"test (1)/test\")\n",
    "X_test, y_test = shuffle_data(X_test, y_test)\n",
    "\n",
    "# One-hot encode test labels\n",
    "y_test_encoded = one_hot_encode(y_test, NUM_CLASSES)\n",
    "\n",
    "def get_batches(X, Y, batch_size):\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        X_batch = X[i:i + batch_size]\n",
    "        Y_batch = Y[i:i + batch_size]\n",
    "        yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c74a697-9122-4d2c-ad8a-8c5b688b71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: (50000, 4096)\n",
      "Test samples: (2000, 4096)\n",
      "Image size: 64 x 64\n",
      "Number of classes: 10\n",
      "Label map: {'bart_simpson': 0, 'charles_montgomery_burns': 1, 'homer_simpson': 2, 'krusty_the_clown': 3, 'lisa_simpson': 4, 'marge_simpson': 5, 'milhouse_van_houten': 6, 'moe_szyslak': 7, 'ned_flanders': 8, 'principal_skinner': 9}\n",
      "X_train: [[0.08235294 0.0627451  0.03137255 ... 0.         0.         0.        ]\n",
      " [0.49411765 0.5137255  0.5568628  ... 0.29803923 0.30588236 0.3019608 ]\n",
      " [0.43529412 0.43529412 0.43529412 ... 0.34117648 0.34509805 0.34509805]\n",
      " ...\n",
      " [0.32156864 0.3137255  0.29411766 ... 0.29411766 0.29411766 0.29411766]\n",
      " [0.47058824 0.47058824 0.46666667 ... 0.52156866 0.52156866 0.52156866]\n",
      " [0.10588235 0.09411765 0.08627451 ... 0.15686275 0.15686275 0.15686275]]\n",
      "y_train_encoded: [[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training samples:\", X_train.shape)\n",
    "print(\"Test samples:\", X_test.shape)\n",
    "print(\"Image size:\", IMAGE_SIZE, \"x\", IMAGE_SIZE)\n",
    "print(\"Number of classes:\", NUM_CLASSES)\n",
    "print(\"Label map:\", label_map)\n",
    "print(f\"X_train: {X_train}\")\n",
    "print(f\"y_train_encoded: {y_train_encoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954264b7-cf3a-4d69-b696-b582cd9c76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "input_size = IMAGE_SIZE * IMAGE_SIZE\n",
    "hidden_size1 = 512\n",
    "hidden_size2 = 128\n",
    "output_size = 10\n",
    "        \n",
    "\n",
    "\n",
    "def leaky_relu(Z, alpha=0.01):\n",
    "    return np.where(Z > 0, Z, alpha * Z)\n",
    "\n",
    "def leaky_relu_deriv(Z, alpha=0.01):\n",
    "    return np.where(Z > 0, 1.0, alpha)\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "    expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "    return expZ / np.sum(expZ, axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6d9784-0918-4d16-bf1c-140574cfb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the parameters\n",
    "np.random.seed(42)\n",
    "\n",
    "W1 = np.random.randn(input_size, hidden_size1) * np.sqrt(2. / input_size)\n",
    "b1 = np.zeros((1, hidden_size1))\n",
    "\n",
    "W2 = np.random.randn(hidden_size1, hidden_size2) * np.sqrt(2. / hidden_size1)\n",
    "b2 = np.zeros((1, hidden_size2))\n",
    "\n",
    "W3 = np.random.randn(hidden_size2, output_size) * np.sqrt(2. / hidden_size2)\n",
    "b3 = np.zeros((1, output_size))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f23b622e-e1cf-436c-97a7-079a9cd77a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, W1, b1, W2, b2, W3, b3):\n",
    "    # Layer 1\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = leaky_relu(Z1)\n",
    "\n",
    "    # Layer 2\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = leaky_relu(Z2)\n",
    "\n",
    "    # Output layer\n",
    "    Z3 = np.dot(A2, W3) + b3\n",
    "    A3 = softmax(Z3)\n",
    "\n",
    "    cache = {\n",
    "        \"Z1\": Z1, \"A1\": A1,\n",
    "        \"Z2\": Z2, \"A2\": A2,\n",
    "        \"Z3\": Z3, \"A3\": A3\n",
    "    }\n",
    "\n",
    "    return A3, cache\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8add6b95-fb5f-4e69-b569-a5727d4abd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(A3, Y):\n",
    "    m = Y.shape[0]\n",
    "    loss = -np.sum(Y * np.log(A3 + 1e-9)) / m\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021b5ac6-2808-4666-aa3f-d9dae2bf589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, W1, b1, W2, b2, W3, b3, cache):\n",
    "    Z1, A1 = cache['Z1'], cache['A1']\n",
    "    Z2, A2 = cache['Z2'], cache['A2']\n",
    "    Z3, A3 = cache['Z3'], cache['A3']  # output layer pre-activation and activation (softmax)\n",
    "    m = X.shape[0]\n",
    "\n",
    "    # Output layer: Softmax + Cross-Entropy derivative\n",
    "    dZ3 = A3 - Y  # (m, output_size)\n",
    "    dW3 = A2.T @ dZ3 / m\n",
    "    db3 = np.sum(dZ3, axis=0, keepdims=True) / m\n",
    "\n",
    "    # Layer 2 (hidden): Leaky ReLU backward\n",
    "    dA2 = dZ3 @ W3.T\n",
    "    dZ2 = dA2 * leaky_relu_deriv(Z2)\n",
    "    dW2 = A1.T @ dZ2 / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "    # Layer 1 (hidden): Leaky ReLU backward\n",
    "    dA1 = dZ2 @ W2.T\n",
    "    dZ1 = dA1 * leaky_relu_deriv(Z1)\n",
    "    dW1 = X.T @ dZ1 / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    return dW1, db1, dW2, db2, dW3, db3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c63b2497-a006-4a70-ac75-24260a6668c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(W1, b1, W2, b2, W3, b3,\n",
    "                      dW1, db1, dW2, db2, dW3, db3,\n",
    "                      learning_rate):\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "\n",
    "    W3 = W3 - learning_rate * dW3\n",
    "    b3 = b3 - learning_rate * db3\n",
    "\n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06acf009-7d06-4d35-8c82-4e4078cc199e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Loss: 2.1305\n",
      "Epoch 11/50 - Loss: 1.4322\n",
      "Epoch 21/50 - Loss: 0.9083\n",
      "Epoch 31/50 - Loss: 0.5691\n",
      "Epoch 41/50 - Loss: 0.3674\n",
      "Epoch 50/50 - Loss: 0.2551\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in get_batches(X_train, y_train_encoded, batch_size):\n",
    "        # Forward pass\n",
    "        A3, cache = forward_propagation(X_batch, W1, b1, W2, b2, W3, b3)\n",
    "\n",
    "        # Compute batch loss\n",
    "        loss = compute_loss(A3, y_batch)\n",
    "        total_loss += loss\n",
    "\n",
    "        # Backward pass\n",
    "        dW1, db1, dW2, db2, dW3, db3 = backward_propagation(\n",
    "            X_batch, y_batch, W1, b1, W2, b2, W3, b3, cache\n",
    "        )\n",
    "\n",
    "        # Update parameters\n",
    "        W1, b1, W2, b2, W3, b3 = update_parameters(\n",
    "            W1, b1, W2, b2, W3, b3,\n",
    "            dW1, db1, dW2, db2, dW3, db3,\n",
    "            learning_rate\n",
    "        )\n",
    "\n",
    "    # Print average loss after each epoch\n",
    "    if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "        avg_loss = total_loss / (X_train.shape[0] // batch_size)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bcc96dc-5b7f-4eb4-836d-7366c7b14c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 47.70%\n"
     ]
    }
   ],
   "source": [
    "def predict(X, W1, b1, W2, b2, W3, b3):\n",
    "    A4, _ = forward_propagation(X, W1, b1, W2, b2, W3, b3)\n",
    "    predictions = np.argmax(A4, axis=1)  # Class with highest probability\n",
    "    return predictions\n",
    "\n",
    "def compute_accuracy(predictions, true_labels):\n",
    "    return np.mean(predictions == true_labels)\n",
    "\n",
    "# After training\n",
    "test_predictions = predict(X_test, W1, b1, W2, b2, W3, b3)\n",
    "accuracy = compute_accuracy(test_predictions, y_test)\n",
    "print(f\"Test set accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748051f-0e1a-42ac-a86c-6154a2289565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
